{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitted by\n",
    "# Nir Vaknin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "from imutils import contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want high contrast between digits and background, therefore we will\n",
    "# read the image, convert it to grayscale and perform threshold\n",
    "ocrTemplate = cv2.imread(r'C:\\Users\\Nir\\Desktop\\OCR_A_font.png')\n",
    "ocrTemplate = cv2.cvtColor(ocrTemplate, cv2.COLOR_BGR2GRAY)\n",
    "ocrTemplate = cv2.threshold(ocrTemplate, 10, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "plt.imshow(ocrTemplate)\n",
    "plt.title('OCR-A font')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from some reason my imutils version is not up to date and i cant install the latest version\n",
    "# hence, i copied imutils.grab_contours as it is\n",
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the digits contours, grab them with the function that\n",
    "# we build at the cell above and sort them left to right\n",
    "refCnts = cv2.findContours(ocrTemplate.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "refCnts = grab_contours(refCnts)\n",
    "refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "digits = {}\n",
    "\n",
    "\n",
    "# loop over all the OCR-A reference contours\n",
    "# compute the digit boundig box (BBox), crop, resize it\n",
    "# and mapping digit name to the roi\n",
    "for (i, c) in enumerate(refCnts):\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    roi = ocrTemplate[y:y + h, x:x + w]\n",
    "    roi = cv2.resize(roi, (115, 175))\n",
    "    digits[i] = roi\n",
    "\n",
    "# initialize a rect and square kernel's for morphological purposes\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 3))\n",
    "squareKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "\n",
    "#plot the roi's and their numeric value\n",
    "plt.figure(figsize=(18,6))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(digits[i])\n",
    "    plt.title(f'numeric value={i}', fontsize = '10')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#begin streaming video (webcam)\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# update the digits prediction to the highest score prediction per digit above all frames\n",
    "finalPredResult = []\n",
    "finalHighestScore = []\n",
    "\n",
    "# the number of frames we want in order to take the predictions with the higest score\n",
    "framesToAnalyze = 0\n",
    "scanCompleted = False\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    raise Exception(\"Could not open video device\") \n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    # cant read from some reason\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # succeed reading from the camera\n",
    "    else: \n",
    "        # Display the resulting frame\n",
    "        displayFrame = cv2.putText(frame, 'Verification CC box:', (130, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (220, 220, 220), 2, lineType=cv2.LINE_AA)\n",
    "        if (scanCompleted):\n",
    "            displayFrame = cv2.rectangle(displayFrame, (130, 110), (510, 350), (0, 255, 0), 4)\n",
    "            cv2.putText(displayFrame, 'SCAN COMPLETED', (400, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), lineType=cv2.LINE_AA)\n",
    "            cv2.putText(displayFrame, '4 last digits Aprox. prediction: ', (150, 380), cv2.FONT_HERSHEY_SIMPLEX, 0.7 ,(220, 220, 220), 2, lineType=cv2.LINE_AA)\n",
    "            cv2.putText(displayFrame, '['+\"  \".join(map(str,finalPredResult))+']', (180, 440), cv2.FONT_HERSHEY_SIMPLEX, 1.4 ,(255, 50, 50), 2, lineType=cv2.LINE_AA)\n",
    "        else:\n",
    "            displayFrame = cv2.rectangle(displayFrame, (130, 110), (510, 350), (0, 0, 255), 2)\n",
    "            cv2.putText(displayFrame, 'Please set CC at the box above', (142, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.7 ,(220, 220, 220), 1, lineType=cv2.LINE_AA)\n",
    "            cv2.putText(displayFrame, (str(framesToAnalyze) + '/15 frames deteced'), (400, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), lineType=cv2.LINE_AA)\n",
    "            \n",
    "       \n",
    "        image = frame[110:350, 130:510]\n",
    "        image = imutils.resize(image, width=300)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # disnoising image\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "        gray = cv2.filter2D(gray, -1, kernel)\n",
    "        \n",
    "        # apply tophat (morphological operator),then compute \n",
    "        # Scharr gradient on it and scale it back to [0,255]\n",
    "        tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, rectKernel)\n",
    "        \n",
    "        # compute the Scharr gradient of the tophat image, then scale\n",
    "        # the rest back into the range [0, 255]\n",
    "        verticalGradient = cv2.Sobel(tophat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "        verticalGradient = np.absolute(verticalGradient)\n",
    "        (minVal, maxVal) = (np.min(verticalGradient), np.max(verticalGradient))\n",
    "        verticalGradient = (255 * ((verticalGradient - minVal) / (maxVal - minVal)))\n",
    "        verticalGradient = verticalGradient.astype(\"uint8\")\n",
    "        \n",
    "        # close the gaps between filtered digits using closing operation\n",
    "        # and binarize image using Otsu thresholding\n",
    "        verticalGradient = cv2.morphologyEx(verticalGradient, cv2.MORPH_CLOSE, rectKernel)\n",
    "        thresh = cv2.threshold(verticalGradient, 0, 255,\n",
    "            cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # apply closing operation again\n",
    "        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, squareKernel)\n",
    "\n",
    "        # find contours,grab them and initalize a digit locations list\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = grab_contours(cnts)\n",
    "        locs = []\n",
    "            \n",
    "            \n",
    "        for (i, c) in enumerate(cnts):\n",
    "            # extract bbox contour and calculate aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            ar = w / float(h)\n",
    "            \n",
    "            # considering most credit cards using the same font size with 4 groups order,\n",
    "            # we can extract the relevant contours based on the width-height and other calculations\n",
    "            if ar > 2.5 and ar < 4.0:\n",
    "                if (w > 40 and w < 55) and (h > 10 and h < 20):\n",
    "                    # the last 4 digits contour mostly located a little bit beneath \n",
    "                    # the half height and at the most right qurter width\n",
    "                    if ((x>200) and (x<250)) and ((y>100) and (y<140)):\n",
    "                        # append bbox roi of digits group to locationss list\n",
    "                        locs.append((x, y, w, h))\n",
    "        \n",
    "        # break from this frame - as we didnt find the 4 digits\n",
    "        if not locs:\n",
    "            cv2.imshow('Frame',displayFrame)        \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # loop over the 4 groupings of 4 digits (in this project only the last 4 digits)\n",
    "        for (i, (gX, gY, gW, gH)) in enumerate(locs):\n",
    "            # initialize the list of group digits\n",
    "            groupPredResult = []\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # crop the 4 digits group roi and threshold it to highlight the digits\n",
    "            group = gray[gY:gY + gH, gX:gX + gW + 2]\n",
    "            group = cv2.threshold(group, 0, 255,\n",
    "                cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            # detect the contours in the 4 digits group image\n",
    "            im4digits, _, _ = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # looking for columns of zeros in im4digits - meaning seperation between digits\n",
    "            (~im4digits.any(axis=0)).any()\n",
    "            seperator = np.where(~im4digits.any(axis=0))[0]\n",
    "            \n",
    "            digitBoxes = []\n",
    "            for i in range(len(seperator)):\n",
    "                # looking for seperators (columns of zeros) that not too close to each other\n",
    "                if (seperator[i] - seperator[i-1] > 5):\n",
    "                    digitBox = im4digits[:, seperator[i-1]:seperator[i]]\n",
    "                    digitBoxes.append(digitBox)\n",
    "            \n",
    "\n",
    "        groupHighestScores = []\n",
    "        # loop over the digit boxes\n",
    "        for c in range(len(digitBoxes)):\n",
    "            roi = cv2.resize(digitBoxes[c], (115, 175))\n",
    "            # initialize a list of template matching scores\n",
    "            scores = []\n",
    "\n",
    "            # loop over the reference digit name and digit ROI\n",
    "            for (digit, digitROI) in digits.items():\n",
    "                # apply correlation-based template matching, take the score, and update the scores list\n",
    "                # use TM_CCOEFF_NORMED (highest accuracy of all 3)\n",
    "                result = cv2.matchTemplate(roi, digitROI,\n",
    "                    cv2.TM_CCOEFF_NORMED)\n",
    "                (_, score, _, _) = cv2.minMaxLoc(result)\n",
    "                scores.append(score)\n",
    "\n",
    "            # the classification for the digit ROI will be the reference\n",
    "            # digit name with the *largest* template matching score\n",
    "            digHighestScore = np.max(scores)\n",
    "            groupHighestScores.append(digHighestScore)\n",
    "            groupPredResult.append(np.argmax(scores))          \n",
    "\n",
    "\n",
    "            # take only the groups that 4 digits (contours) has found in it\n",
    "            if (len(groupPredResult) == 4):\n",
    "                # enough frames to analyze\n",
    "                framesToAnalyze += 1\n",
    "                if (framesToAnalyze == 15):\n",
    "                    scanCompleted = True\n",
    "\n",
    "                # if we didnt detected 4 digits yet\n",
    "                if not finalHighestScore:\n",
    "                    finalPredResult = groupPredResult\n",
    "                    finalHighestScore = groupHighestScores\n",
    "                else:\n",
    "                    for i in range(4):\n",
    "                        if (finalHighestScore[i] < groupHighestScores[i]):\n",
    "                            finalHighestScore[i] = groupHighestScores[i]\n",
    "                            finalPredResult[i] = groupPredResult[i] \n",
    "                \n",
    "                # plot the the digits prediction and score from the frames that have been \n",
    "                # detected for you to see validation and prediction over the frames \n",
    "                print('_____________________________________________________')\n",
    "                for i in range(4):\n",
    "                    print('digit #{} | prediction: {},  score: {}'.format(i+1, finalPredResult[i], finalHighestScore[i]))\n",
    "\n",
    "        cv2.imshow('Frame',displayFrame)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the score of the predicted numbers (the one's with the highest score)\n",
    "print('final predictions for each digit and their scores :')\n",
    "for i in range(4):\n",
    "    print('digit #{} | prediction: {},  score: {}'.format(i+1, finalPredResult[i], finalHighestScore[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
